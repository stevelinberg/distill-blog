<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007ba5; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #007ba5; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #007ba5; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #5e5e5e; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>


  <!--radix_placeholder_meta_tags-->
  <title>MS797 Glossary</title>

  <meta property="description" itemprop="description" content="Glossary for MS797 coursework"/>


  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2022-01-30"/>
  <meta property="article:created" itemprop="dateCreated" content="2022-01-30"/>
  <meta name="article:author" content="Steve Linberg"/>

  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="MS797 Glossary"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="Glossary for MS797 coursework"/>
  <meta property="og:locale" content="en_US"/>

  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="MS797 Glossary"/>
  <meta property="twitter:description" content="Glossary for MS797 coursework"/>

  <!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->

  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","output","categories"]}},"value":[{"type":"character","attributes":{},"value":["MS797 Glossary"]},{"type":"character","attributes":{},"value":["Glossary for MS797 coursework\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url"]}},"value":[{"type":"character","attributes":{},"value":["Steve Linberg"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":[]}},"value":[]}]}]},{"type":"character","attributes":{},"value":["2022-01-30"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","toc"]}},"value":[{"type":"logical","attributes":{},"value":[false]},{"type":"logical","attributes":{},"value":[true]}]}]},{"type":"character","attributes":{},"value":["machine learning","glossary"]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["ms797-glossary_files/anchor-4.2.2/anchor.min.js","ms797-glossary_files/bowser-1.9.3/bowser.min.js","ms797-glossary_files/distill-2.2.21/template.v2.js","ms797-glossary_files/header-attrs-2.11/header-attrs.js","ms797-glossary_files/jquery-3.6.0/jquery-3.6.0.js","ms797-glossary_files/jquery-3.6.0/jquery-3.6.0.min.js","ms797-glossary_files/jquery-3.6.0/jquery-3.6.0.min.map","ms797-glossary_files/popper-2.6.0/popper.min.js","ms797-glossary_files/tippy-6.2.7/tippy-bundle.umd.min.js","ms797-glossary_files/tippy-6.2.7/tippy-light-border.css","ms797-glossary_files/tippy-6.2.7/tippy.css","ms797-glossary_files/tippy-6.2.7/tippy.umd.min.js","ms797-glossary_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

  <style type="text/css">

  body {
    background-color: white;
  }

  .pandoc-table {
    width: 100%;
  }

  .pandoc-table>caption {
    margin-bottom: 10px;
  }

  .pandoc-table th:not([align]) {
    text-align: left;
  }

  .pagedtable-footer {
    font-size: 15px;
  }

  d-byline .byline {
    grid-template-columns: 2fr 2fr;
  }

  d-byline .byline h3 {
    margin-block-start: 1.5em;
  }

  d-byline .byline .authors-affiliations h3 {
    margin-block-start: 0.5em;
  }

  .authors-affiliations .orcid-id {
    width: 16px;
    height:16px;
    margin-left: 4px;
    margin-right: 4px;
    vertical-align: middle;
    padding-bottom: 2px;
  }

  d-title .dt-tags {
    margin-top: 1em;
    grid-column: text;
  }

  .dt-tags .dt-tag {
    text-decoration: none;
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0em 0.4em;
    margin-right: 0.5em;
    margin-bottom: 0.4em;
    font-size: 70%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  d-article table.gt_table td,
  d-article table.gt_table th {
    border-bottom: none;
  }

  .html-widget {
    margin-bottom: 2.0em;
  }

  .l-screen-inset {
    padding-right: 16px;
  }

  .l-screen .caption {
    margin-left: 10px;
  }

  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .shaded-content {
    background: white;
  }

  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }

  .hidden {
    display: none !important;
  }

  d-article {
    padding-top: 2.5rem;
    padding-bottom: 30px;
  }

  d-appendix {
    padding-top: 30px;
  }

  d-article>p>img {
    width: 100%;
  }

  d-article h2 {
    margin: 1rem 0 1.5rem 0;
  }

  d-article h3 {
    margin-top: 1.5rem;
  }

  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }

  /* Tweak code blocks */

  d-article div.sourceCode code,
  d-article pre code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: auto;
  }

  d-article div.sourceCode {
    background-color: white;
  }

  d-article div.sourceCode pre {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }

  d-article pre {
    font-size: 12px;
    color: black;
    background: none;
    margin-top: 0;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  d-article pre a {
    border-bottom: none;
  }

  d-article pre a:hover {
    border-bottom: none;
    text-decoration: underline;
  }

  d-article details {
    grid-column: text;
    margin-bottom: 0.8em;
  }

  @media(min-width: 768px) {

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: visible !important;
  }

  d-article div.sourceCode pre {
    padding-left: 18px;
    font-size: 14px;
  }

  d-article pre {
    font-size: 14px;
  }

  }

  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  /* CSS for d-contents */

  .d-contents {
    grid-column: text;
    color: rgba(0,0,0,0.8);
    font-size: 0.9em;
    padding-bottom: 1em;
    margin-bottom: 1em;
    padding-bottom: 0.5em;
    margin-bottom: 1em;
    padding-left: 0.25em;
    justify-self: start;
  }

  @media(min-width: 1000px) {
    .d-contents.d-contents-float {
      height: 0;
      grid-column-start: 1;
      grid-column-end: 4;
      justify-self: center;
      padding-right: 3em;
      padding-left: 2em;
    }
  }

  .d-contents nav h3 {
    font-size: 18px;
    margin-top: 0;
    margin-bottom: 1em;
  }

  .d-contents li {
    list-style-type: none
  }

  .d-contents nav > ul {
    padding-left: 0;
  }

  .d-contents ul {
    padding-left: 1em
  }

  .d-contents nav ul li {
    margin-top: 0.6em;
    margin-bottom: 0.2em;
  }

  .d-contents nav a {
    font-size: 13px;
    border-bottom: none;
    text-decoration: none
    color: rgba(0, 0, 0, 0.8);
  }

  .d-contents nav a:hover {
    text-decoration: underline solid rgba(0, 0, 0, 0.6)
  }

  .d-contents nav > ul > li > a {
    font-weight: 600;
  }

  .d-contents nav > ul > li > ul {
    font-weight: inherit;
  }

  .d-contents nav > ul > li > ul > li {
    margin-top: 0.2em;
  }


  .d-contents nav ul {
    margin-top: 0;
    margin-bottom: 0.25em;
  }

  .d-article-with-toc h2:nth-child(2) {
    margin-top: 0;
  }


  /* Figure */

  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }

  .figure img {
    width: 100%;
  }

  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }

  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }

  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }

  /* Citations */

  d-article .citation {
    color: inherit;
    cursor: inherit;
  }

  div.hanging-indent{
    margin-left: 1em; text-indent: -1em;
  }

  /* Citation hover box */

  .tippy-box[data-theme~=light-border] {
    background-color: rgba(250, 250, 250, 0.95);
  }

  .tippy-content > p {
    margin-bottom: 0;
    padding: 2px;
  }


  /* Tweak 1000px media break to show more text */

  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }

    .grid {
      grid-column-gap: 16px;
    }

    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }

  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }

    .grid {
      grid-column-gap: 32px;
    }
  }


  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */

  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  /* Include appendix styles here so they can be overridden */

  d-appendix {
    contain: layout style;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-top: 60px;
    margin-bottom: 0;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    color: rgba(0,0,0,0.5);
    padding-top: 60px;
    padding-bottom: 48px;
  }

  d-appendix h3 {
    grid-column: page-start / text-start;
    font-size: 15px;
    font-weight: 500;
    margin-top: 1em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.65);
  }

  d-appendix h3 + * {
    margin-top: 1em;
  }

  d-appendix ol {
    padding: 0 0 0 15px;
  }

  @media (min-width: 768px) {
    d-appendix ol {
      padding: 0 0 0 30px;
      margin-left: -30px;
    }
  }

  d-appendix li {
    margin-bottom: 1em;
  }

  d-appendix a {
    color: rgba(0, 0, 0, 0.6);
  }

  d-appendix > * {
    grid-column: text;
  }

  d-appendix > d-footnote-list,
  d-appendix > d-citation-list,
  d-appendix > distill-appendix {
    grid-column: screen;
  }

  /* Include footnote styles here so they can be overridden */

  d-footnote-list {
    contain: layout style;
  }

  d-footnote-list > * {
    grid-column: text;
  }

  d-footnote-list a.footnote-backlink {
    color: rgba(0,0,0,0.3);
    padding-left: 0.5em;
  }



  /* Anchor.js */

  .anchorjs-link {
    /*transition: all .25s linear; */
    text-decoration: none;
    border-bottom: none;
  }
  *:hover > .anchorjs-link {
    margin-left: -1.125em !important;
    text-decoration: none;
    border-bottom: none;
  }

  /* Social footer */

  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }

  .disqus-comments {
    margin-right: 30px;
  }

  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }

  #disqus_thread {
    margin-top: 30px;
  }

  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }

  .article-sharing a:hover {
    border-bottom: none;
  }

  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }

  .subscribe p {
    margin-bottom: 0.5em;
  }


  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }


  .sidebar-section.custom {
    font-size: 12px;
    line-height: 1.6em;
  }

  .custom p {
    margin-bottom: 0.5em;
  }

  /* Styles for listing layout (hide title) */
  .layout-listing d-title, .layout-listing .d-title {
    display: none;
  }

  /* Styles for posts lists (not auto-injected) */


  .posts-with-sidebar {
    padding-left: 45px;
    padding-right: 45px;
  }

  .posts-list .description h2,
  .posts-list .description p {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  }

  .posts-list .description h2 {
    font-weight: 700;
    border-bottom: none;
    padding-bottom: 0;
  }

  .posts-list h2.post-tag {
    border-bottom: 1px solid rgba(0, 0, 0, 0.2);
    padding-bottom: 12px;
  }
  .posts-list {
    margin-top: 60px;
    margin-bottom: 24px;
  }

  .posts-list .post-preview {
    text-decoration: none;
    overflow: hidden;
    display: block;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
    padding: 24px 0;
  }

  .post-preview-last {
    border-bottom: none !important;
  }

  .posts-list .posts-list-caption {
    grid-column: screen;
    font-weight: 400;
  }

  .posts-list .post-preview h2 {
    margin: 0 0 6px 0;
    line-height: 1.2em;
    font-style: normal;
    font-size: 24px;
  }

  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.4em;
    font-size: 16px;
  }

  .posts-list .post-preview .thumbnail {
    box-sizing: border-box;
    margin-bottom: 24px;
    position: relative;
    max-width: 500px;
  }
  .posts-list .post-preview img {
    width: 100%;
    display: block;
  }

  .posts-list .metadata {
    font-size: 12px;
    line-height: 1.4em;
    margin-bottom: 18px;
  }

  .posts-list .metadata > * {
    display: inline-block;
  }

  .posts-list .metadata .publishedDate {
    margin-right: 2em;
  }

  .posts-list .metadata .dt-authors {
    display: block;
    margin-top: 0.3em;
    margin-right: 2em;
  }

  .posts-list .dt-tags {
    display: block;
    line-height: 1em;
  }

  .posts-list .dt-tags .dt-tag {
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0.3em 0.4em;
    margin-right: 0.2em;
    margin-bottom: 0.4em;
    font-size: 60%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  .posts-list img {
    opacity: 1;
  }

  .posts-list img[data-src] {
    opacity: 0;
  }

  .posts-more {
    clear: both;
  }


  .posts-sidebar {
    font-size: 16px;
  }

  .posts-sidebar h3 {
    font-size: 16px;
    margin-top: 0;
    margin-bottom: 0.5em;
    font-weight: 400;
    text-transform: uppercase;
  }

  .sidebar-section {
    margin-bottom: 30px;
  }

  .categories ul {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }

  .categories li {
    color: rgba(0, 0, 0, 0.8);
    margin-bottom: 0;
  }

  .categories li>a {
    border-bottom: none;
  }

  .categories li>a:hover {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  }

  .categories .active {
    font-weight: 600;
  }

  .categories .category-count {
    color: rgba(0, 0, 0, 0.4);
  }


  @media(min-width: 768px) {
    .posts-list .post-preview h2 {
      font-size: 26px;
    }
    .posts-list .post-preview .thumbnail {
      float: right;
      width: 30%;
      margin-bottom: 0;
    }
    .posts-list .post-preview .description {
      float: left;
      width: 45%;
    }
    .posts-list .post-preview .metadata {
      float: left;
      width: 20%;
      margin-top: 8px;
    }
    .posts-list .post-preview p {
      margin: 0 0 12px 0;
      line-height: 1.5em;
      font-size: 16px;
    }
    .posts-with-sidebar .posts-list {
      float: left;
      width: 75%;
    }
    .posts-with-sidebar .posts-sidebar {
      float: right;
      width: 20%;
      margin-top: 60px;
      padding-top: 24px;
      padding-bottom: 24px;
    }
  }


  /* Improve display for browsers without grid (IE/Edge <= 15) */

  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }

  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }

  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }

  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }

  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }

  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }

  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }


  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }

  .downlevel .footnotes ol {
    padding-left: 13px;
  }

  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }

  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }

  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }

  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  .downlevel .posts-list .post-preview {
    color: inherit;
  }



  </style>

  <script type="application/javascript">

  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }

  // show body when load is complete
  function on_load_complete() {

    // add anchors
    if (window.anchors) {
      window.anchors.options.placement = 'left';
      window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
    }


    // set body to visible
    document.body.style.visibility = 'visible';

    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }

    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }

  function init_distill() {

    init_common();

    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);

    // create d-title
    $('.d-title').changeElementType('d-title');

    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);

    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();

    // move posts container into article
    $('.posts-container').appendTo($('d-article'));

    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');

    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;

    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();

    // move refs into #references-listing
    $('#references-listing').replaceWith($('#refs'));

    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-contents a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });

    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');

    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {

      // capture layout
      var layout = $(this).attr('data-layout');

      // apply layout to markdown level block elements
      var elements = $(this).children().not('details, div.sourceCode, pre, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });


      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });

    // remove code block used to force  highlighting css
    $('.distill-force-highlighting-css').parent().remove();

    // remove empty line numbers inserted by pandoc when using a
    // custom syntax highlighting theme
    $('code.sourceCode a:empty').remove();

    // load distill framework
    load_distill_framework();

    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {

      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;

      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');

      // article with toc class
      $('.d-contents').parent().addClass('d-article-with-toc');

      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

      // add orcid ids
      $('.authors-affiliations').find('.author').each(function(i, el) {
        var orcid_id = front_matter.authors[i].orcidID;
        if (orcid_id) {
          var a = $('<a></a>');
          a.attr('href', 'https://orcid.org/' + orcid_id);
          var img = $('<img></img>');
          img.addClass('orcid-id');
          img.attr('alt', 'ORCID ID');
          img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
          a.append(img);
          $(this).append(a);
        }
      });

      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }

      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");

      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }

       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }

      // remove d-appendix and d-footnote-list local styles
      $('d-appendix > style:first-child').remove();
      $('d-footnote-list > style:first-child').remove();

      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();

      // hoverable references
      $('span.citation[data-cites]').each(function() {
        var refs = $(this).attr('data-cites').split(" ");
        var refHtml = refs.map(function(ref) {
          return "<p>" + $('#ref-' + ref).html() + "</p>";
        }).join("\n");
        window.tippy(this, {
          allowHTML: true,
          content: refHtml,
          maxWidth: 500,
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        });
      });

      // clear polling timer
      clearInterval(tid);

      // show body now that everything is ready
      on_load_complete();
    }

    var tid = setInterval(distill_post_process, 50);
    distill_post_process();

  }

  function init_downlevel() {

    init_common();

     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));

    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;

    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();

    // remove toc
    $('.d-contents').remove();

    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });


    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);

    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();

    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });

    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));

    $('body').addClass('downlevel');

    on_load_complete();
  }


  function init_common() {

    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};

        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });

        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);

    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});

    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });

      }
    });

    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });

    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }

    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');

    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");

    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();

    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }

  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });

  </script>

  <!--/radix_placeholder_distill-->
  <script src="ms797-glossary_files/header-attrs-2.11/header-attrs.js"></script>
  <script src="ms797-glossary_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
  <script src="ms797-glossary_files/popper-2.6.0/popper.min.js"></script>
  <link href="ms797-glossary_files/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="ms797-glossary_files/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="ms797-glossary_files/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="ms797-glossary_files/anchor-4.2.2/anchor.min.js"></script>
  <script src="ms797-glossary_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="ms797-glossary_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="ms797-glossary_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"MS797 Glossary","description":"Glossary for MS797 coursework","authors":[{"author":"Steve Linberg","authorURL":{},"affiliation":"&nbsp;","affiliationURL":"#","orcidID":""}],"publishedDate":"2022-01-30T00:00:00.000-05:00","citationText":"Linberg, 2022"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>MS797 Glossary</h1>
<!--radix_placeholder_categories-->
<div class="dt-tags">
<div class="dt=tag">machine learning</div>
<div class="dt=tag">glossary</div>
</div>
<!--/radix_placeholder_categories-->
<p><p>Glossary for MS797 coursework</p></p>
</div>

<div class="d-byline">
  Steve Linberg true 
  
<br/>2022-01-30
</div>

<div class="d-article">
<div class="d-contents d-contents-float">
<nav class="l-text toc figcaption" id="TOC">
<h3>Contents</h3>
<ul>
<li><a href="#chapter-2">Chapter 2</a></li>
<li><a href="#chapter-3">Chapter 3</a></li>
<li><a href="#chapter-4">Chapter 4</a></li>
<li><a href="#chapter-5">Chapter 5</a></li>
</ul>
</nav>
</div>
<p style="background: #eee">
<a href="/"><i class="fas fa-home"></i></a> &gt; Academics &gt; <a href="../ms797/index.html">MS797</a> &gt; Glossary
</p>
<p>Page numbers in parenthesis after terms, from <a href="https://www.statlearning.com/">ISLR</a> 2nd edition. Non-page numbers indicate other sources; “biostats” references material from Biostatistics 690Z (Health Data Science: Statistical Modeling), fall 2021.</p>
<h2 id="chapter-2">Chapter 2</h2>
<dl>
<dt>input variable (15)</dt>
<dd>also <em>predictor</em>, <em>independent variable</em>, <em>feature</em>; usually written <span class="math inline">\(X_1, X_2\)</span>, etc. The parameter or parameters we are testing to see if they are related to or affect the output.
</dd>
<dt>output variable (15)</dt>
<dd>also <em>response</em>, <em>dependent variable</em>; usually written <span class="math inline">\(Y\)</span>. The outcome being measured.
</dd>
<dt>error term (16)</dt>
<dd><span class="math inline">\(\epsilon\)</span> in the equation<br />
<span class="math display">\[Y = f(X) + \epsilon\]</span> a random quantity of inaccuracy, <em>independent of X</em> and with <em>mean 0</em>.
</dd>
<dt>systematic (16)</dt>
<dd><span class="math inline">\(f\)</span> in the equation<br />
<span class="math display">\[Y = f(X) + \epsilon\]</span> the function that describes the (systematic) information <span class="math inline">\(X\)</span> provides about <span class="math inline">\(Y\)</span>. This plus the error term equals <span class="math inline">\(Y\)</span>.
</dd>
<dt>reducible error (18)</dt>
<dd>The amount of the error <span class="math inline">\(\epsilon\)</span> that could be eliminated by improving our estimator <span class="math inline">\(\hat{f}\)</span>; the difference between <span class="math inline">\(\hat{f}\)</span> and <span class="math inline">\(f\)</span>. This book and course is mostly about ways to minimize the reducible error.
</dd>
<dt>irreducible error (18)</dt>
<dd>The amount of <span class="math inline">\(\epsilon\)</span> that could not be reduced even if <span class="math inline">\(f\)</span> was a perfect estimator of <span class="math inline">\(Y\)</span>. Always greater than 0. Could be due to hidden variables in <span class="math inline">\(\epsilon\)</span>, or random fluctuations in Y, like a measure of “[a] patient’s general feeling of well-being on that day”.
</dd>
<dt>expected value (19)</dt>
<dd><em>average value</em> of an expected measure.
</dd>
<dt>training data (21)</dt>
<dd>data used to develop the model for estimating <span class="math inline">\(f\)</span>.
</dd>
<dt>parametric methods (21)</dt>
<dd>A model based on one or more input parameters, that yields a value for Y, as in: <span class="math display">\[f(X) = \beta_0 + \beta_1X_1 + \beta_2X_2 + \dots + \beta_pX_p\]</span> <span class="math display">\[Y \approx \beta_0 + \beta_1X_1 + \beta_2X_2 + \dots + \beta_pX_p\]</span> <span class="math display">\[\text{income} \approx \beta_0 + \beta_1 \times \text{education} + \beta_2 \times \text{seniority}\]</span> This creates a predictive, <em>inflexible</em> model which usually does not match the true <span class="math inline">\(f\)</span>, but which has advantages of simplicity and interpretability. It can be used to predict values for <span class="math inline">\(Y\)</span> based on its parameters, or inputs. Linear and logistic regression are parametric.
</dd>
<dt>non-parametric methods (23)</dt>
<dd>methods that do not attempt to estimate <span class="math inline">\(f\)</span>. More flexible and have the potential to very closely match observations, but with the risk of <em>overfitting</em> the data and increasing the <em>variance</em> of subsequent observations. They require much more data than parametric models, and may be difficult to interpret, K-Nearest Neighbor and Support Vector Machines are non-parametric.
</dd>
<dt>prediction (26)</dt>
<dd>seeking to guess the value of an response variable <span class="math inline">\(y_i\)</span> given a set of observations and a predictor <span class="math inline">\(f\)</span>.
</dd>
<dt>inference (26)</dt>
<dd>a model that seems to better understand the relationship between the response and the predictors.
</dd>
<dt>supervised learning (26)</dt>
<dd>a category of model that allows us to guess a <span class="math inline">\(y_i\)</span> response to a set of predictor measurements <span class="math inline">\(x_i, i = 1, \dots, n\)</span>.
</dd>
<dt>unsupervised learning (26)</dt>
<dd>a category of model in which there are observations/measurements <span class="math inline">\(x_i, i = 1, \dots, n\)</span>, but no associated response <span class="math inline">\(y_i\)</span>. Linear regression cannot be used because there is no response variable to predict.
</dd>
<dt>cluster analysis (27)</dt>
<dd>in unsupervised learning, a statistical method for determining whether a set of observations can be divided into “relatively distinct groups,” looking for similarities within the groups. (Topic modeling may be an example of this.)
</dd>
<dt>quantitative variables (28)</dt>
<dd>numeric values; age, height, weight, quantity. Usually the response variable type for regression problems.
</dd>
<dt>qualitative variables (28)</dt>
<dd>also <em>categorical</em>: values from a discrete set. Eye color, name, yes/no. Usually the response variable type for classification problems.
</dd>
<dt>regression problems (28)</dt>
<dd>problems with quantitative response variables. Given predictors foo, bar, and baz, how big is the frob?
</dd>
<dt>classification problems (28)</dt>
<dd>problems with qualitative response variables. Given predictors foo, bar, and baz, is the outcome likely to be a frob, a frib or a freeb?
</dd>
<dt>mean squared error (MSE) (29)</dt>
<dd>the average squared error for a set of observations: <span class="math display">\[MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{f}(x_i))^2\]</span> MSE is small if the predicted responses are close to the true responses, and larger as it becomes less accurate; computed from training data, and Gareth <em>et al.</em> suggest it should be called <em>training MSE</em>.
</dd>
<dt>variance (34)</dt>
<dd><em>“the amount by which <span class="math inline">\(\hat{f}\)</span> would change if we estimated it using a different training data set”</em>
</dd>
<dt>bias (35)</dt>
<dd><em>“the error that is introduced by approximating a real-life problem, which may be extremely complicated, by a much simpler model”</em>, as in the error from the (presumed) linearity of a regression against non-linear data whose complexity it does not capture. More flexible models increase variance and decrease bias.
</dd>
<dt>bias-variance trade-off (36)</dt>
<dd>The tension in seeking the best model for the data between missing the true <span class="math inline">\(f\)</span> with an overly simple (biased) model, vs. an overfitted model with too much variance from mapping too closely to test data.
</dd>
<dt>error rate (37)</dt>
<dd>In classification, the proportion of classifications that are mistakes. <span class="math display">\[\frac{1}{n}\sum_{i=1}^{n}I(y_i \neq \hat{y}_i)\]</span> <span class="math inline">\(I\)</span> is 1 if <span class="math inline">\(y_i \neq \hat{y}_i\)</span> - if the guess for any given <span class="math inline">\(y\)</span> is wrong. The error rate is the percentage of incorrect classifications. Also the <em>training erorr rate</em>.
</dd>
<dt>indicator variable (37)</dt>
<dd><span class="math inline">\(I\)</span> in the error rate definition above; a logical variable indicating the presence or absence of a characteristic or trait (such as an accurate classification).
</dd>
<dt>test error rate (37)</dt>
<dd>like the <em>training error rate</em> but applied to the test data. Uses <span class="math inline">\(\text{Ave}\)</span> instead of sum notation: <span class="math display">\[\text{Ave}(I(y_0 \neq \hat{y}_0))\]</span> <span class="math inline">\(\hat{y}_0\)</span> is the predicted class label from the classifier.
</dd>
<dt>conditional probability (37)</dt>
<dd>The chance that <span class="math inline">\(Y = j\)</span> given an observed <span class="math inline">\(x_0\)</span>, as in the <em>Bayes classifier</em>: <span class="math display">\[\text{Pr}(Y = j|X = x_0)\]</span> In a two-class, yes/no classifier, we decide based on whether <span class="math inline">\(\text{Pr}(Y = j|X = x_0)\)</span> is <span class="math inline">\(&gt; 0.5\)</span>, or not. Note that <span class="math inline">\(Y\)</span> is the class, as in “ham”/“spam”, not a <span class="math inline">\(y\)</span>-axis coordinate.
</dd>
<dt>Bayes decision boundary (38)</dt>
<dd>a visual depiction of the line of 50% probability dividing (exactly two?) classes in a two-dimensional space
</dd>
<dt>Bayes error rate (38)</dt>
<dd>the expected (average) probability of classification error over all values of X in a data set. <span class="math display">\[1 - E(\underset{j}{maxPr}(Y = j|X))\]</span> The <span class="math inline">\(\underset{j}{maxPr}\)</span> whichever of the <span class="math inline">\(j\)</span> classes has the highest probability for any given value of <span class="math inline">\(X\)</span>. Again, <span class="math inline">\(Y\)</span> is not a y-axis coordinate of a two-dimensional space, it’s the <em>class</em> of the classification: “yes”/“no”, “ham”/“spam”, “infected”/“not infected”. Also: <em>“The Bayes error rate is analogous to the irreducible error, discussed earlier.”</em>
</dd>
<dt>K-nearest-neighbors (KNN) (39)</dt>
<dd>a classifier that assigns a class Y to an observation based on the population proportions of its nearest neighbors; a circular “neighborhood” on a two-dimensional plot. It looks at actual data points that have been classified, and asks what any given non-classified point would be classified as based on its nearest neighbors.
</dd>
</dl>
<h2 id="chapter-3">Chapter 3</h2>
<dl>
<dt>Synergy effect / interaction effect (60)</dt>
<dd>when two or more predictors affect each other as well as the outcome; when 50k each in TV or radio ads give different results than 100k in either one
</dd>
<dt>Simple linear regression</dt>
<dd>the simplest model, predicting <span class="math inline">\(Y\)</span> from a single predictor <span class="math inline">\(X\)</span>. <span class="math display">\[Y \approx \beta_0 + \beta_1X\]</span> <span class="math inline">\(\approx\)</span> = “is approximately modeled as”
</dd>
<dt>least squares (61)</dt>
<dd>the most common measure of closeness of a regression line to its data points, the sum of squares of the distances between the points and the closest point on the line (directly above or below)
</dd>
<dt>residual (61)</dt>
<dd>the difference between <span class="math inline">\(y_i\)</span> and <span class="math inline">\(\hat{y}_i\)</span>, also <span class="math inline">\(e_i\)</span>; the difference between the <span class="math inline">\(i\)</span>th response variable and the <span class="math inline">\(i\)</span>th response variable predicted by the model
</dd>
<dt>residual sum of squares (RSS) (62)</dt>
<dd>the sum of the squared residuals for each point on the regression line <span class="math display">\[\text{RSS} = e_1^2 + e_2^2 + \dots + e_n^2\]</span> Formulas for <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span> are on p. 62
</dd>
<dt>intercept (<span class="math inline">\(\beta_0\)</span>) (63)</dt>
<dd>the expected value of <span class="math inline">\(Y\)</span> when <span class="math inline">\(X = 0\)</span>
</dd>
<dt>slope (<span class="math inline">\(\beta_1\)</span>) (63)</dt>
<dd>the average increase in <span class="math inline">\(Y\)</span> associated with a one-unit increase in <span class="math inline">\(X\)</span>
</dd>
<dt>error term (<span class="math inline">\(\epsilon\)</span>) (63)</dt>
<dd>whatever we missed with the model, due to the true model not being linear (it almost never is), measurement error, or other variables that cause variation in <span class="math inline">\(Y\)</span>
</dd>
<dt>population regression line (63)</dt>
<dd>“the best linear approximation to the true relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>” <span class="math display">\[Y = \beta_0 + \beta_1X + \epsilon\]</span> least squares line (63)
</dd>
<dd>the regression line made of the least-squares estimates for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>
</dd>
<dt>bias (65)</dt>
<dd>in an estimator, something that systematically misses the true parameter; for an unbiased estimator, <span class="math inline">\(\hat{\mu} = \mu\)</span> when averaged over (huge) numbers of observations
</dd>
<dt>standard error (SE) (65)</dt>
<dd>the average amount that an estimate <span class="math inline">\(\hat{\mu}\)</span> (sample mean) differs from the actual value of <span class="math inline">\(\mu\)</span> (population mean) <span class="math display">\[\text{Var}(\hat{\mu}) = \text{SE}(\hat{\mu})^2 = \frac{\sigma^2}{n} (\text{also} = \frac{\sigma}{\sqrt{n}})\]</span> <span class="math inline">\(\sigma\)</span> is “the standard deviation of each of the realizations <span class="math inline">\(y_i\)</span> of <span class="math inline">\(Y\)</span>. Since <span class="math inline">\(\sigma^2\)</span> is divided by <span class="math inline">\(n\)</span>, the standard error shrinks as observations increase. It represents the amount we would expect means of additional samples to”jump around" simply due to random chance and the limitations of the model’s accuracy.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>
</dd>
<dt>residual standard error (RSE) (66)</dt>
<dd>the estimate of <span class="math inline">\(\sigma\)</span> <span class="math display">\[\text{RSE} = \sqrt{RSS / (n-2)}\]</span>
</dd>
<dt>confidence interval (66)</dt>
<dd>a range of values within which we have a measured probability (often 95%) of containing the true value of the parameter; a 95% confidence interval in linear regression takes the form <span class="math display">\[\hat{\beta_1} \pm 2 \cdot \text{SE}(\hat{\beta_1})\]</span>
</dd>
<dt>t-statistic (67)</dt>
<dd>the number of standard deviations that <span class="math inline">\(\hat{\beta_1}\)</span> is away from <span class="math inline">\(0\)</span>. <span class="math display">\[t = \frac{{\hat{\beta_1}} - 0}{\text{SE}(\hat{\beta_1})}\]</span> For there to be a relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, <span class="math inline">\(\hat{\beta_1}\)</span> has to be nonzero (i.e. have a slope). The standard error (SE) of <span class="math inline">\(\hat{\beta_1}\)</span> (in the denominator above) measures its accuracy; if it is small, then <span class="math inline">\(t\)</span> will be larger, and if it is large, then <span class="math inline">\(t\)</span> will be smaller. <span class="math inline">\(t\)</span> is around 2 for a p-value of 0.05 (actually about 1.96, as 2 standard deviations is 95.45% of a normal distribution), and around 2.75 for a p-value of 0.01.
</dd>
<dt>p-value (67)</dt>
<dd>the probability of observing a value greater than <span class="math inline">\(|t|\)</span> by chance.
</dd>
<dt>model sum of squares (MSS) (biostats)</dt>
<dd>Also sometimes <strong>ESS</strong>, “explained sum of squares”: the total variance in the response <span class="math inline">\(Y\)</span> that can be accounted for by the model <span class="math display">\[\text{MSS} = \sum(\hat{y_i} - \bar{y})^2\]</span>
</dd>
<dt>residual sum of squares (RSS) (biostats)</dt>
<dd>the total variance in the response <span class="math inline">\(Y\)</span> that cannot be accounted for by the model <span class="math display">\[\text{RSS} = \sum(y_i - \hat{y_i})^2\]</span> also <span class="math display">\[\text{RSS} = e_i^2 + e_2^2 + \dots + e_n^2\]</span> or <span class="math display">\[\text{RSS} = (y_1 - \hat{\beta_0} - {\hat{\beta_1}x_1})^2 + (y_2 - \hat{\beta_0} - {\hat{\beta_1}x_2})^ + \dots + (y_n - \hat{\beta_0} - {\hat{\beta_1}x_n})^2\]</span>
</dd>
<dt>total sum of squares (TSS) (70)</dt>
<dd>the total variance in the response <span class="math inline">\(Y\)</span>; the total variability of the response about its mean <span class="math display">\[\text{TSS} = \sum(y_i - \bar{y})^2\]</span> compare with RSS, the amount of variability left unexplained after the regression. TSS - RSS is the amount of variability (or error) explained by the regression (MSS).
</dd>
</dl>
<p><strong>NOTE</strong>: there is a nice visual <a href="https://stats.stackexchange.com/a/512216/338749">here on stackexchange</a>; if anybody knows how to tell Zotero to use a custom bibtex citation entry over the ones it generates, please let me know so I can integrate it better here :frown:</p>
<dl>
<dt><span class="math inline">\(R^2\)</span> statistic (70)</dt>
<dd>the proportion of variance in <span class="math inline">\(Y\)</span> explained by <span class="math inline">\(X\)</span>, a range from 0 to 1 <span class="math display">\[R^2 = \frac{\text{TSS - RSS}}{\text{TSS}} = 1 - \frac{\text{RSS}}{\text{TSS}}\]</span> <span class="math inline">\(R^2\)</span> values close to 1 indicate a regression that explains a lot of the variability in the response, and a stronger model. A value close to 0 indicates that the regression doesn’t explain much of the variability.
</dd>
<dt>correlation (70)</dt>
<dd>a measure of the linearity of the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>; values close to 0 indicate weak-to-no relationship, values near 1 or -1 indicate strong positive or negative correlation <span class="math display">\[\text{Cor(X, Y)} = {\frac {\sum _{i=1}^{n}(x_{i}-{\bar {x}})(y_{i}-{\bar {y}})}{{\sqrt {\sum _{i=1}^{n}(x_{i}-{\bar {x}})^{2}}}{\sqrt {\sum _{i=1}^{n}(y_{i}-{\bar {y}})^{2}}}}}\]</span>
</dd>
<dt>standard linear regression model (72)</dt>
<dd>The modal used for standard linear models, used to interpret the the effect on <span class="math inline">\(Y\)</span> of a one-unit increase in any predictor <span class="math inline">\(\beta_j\)</span> while holding all other predictors constant <span class="math display">\[Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \dots + \beta_pX_p + \epsilon\]</span>
</dd>
<dt>variable selection (78)</dt>
<dd>the task of refining a model to include only the variables associated with the response
</dd>
<dt>null model (79)</dt>
<dd>a model that conatins an intercept, but no predictors; used as a first stage in forward selection
</dd>
<dt>forward selection (79)</dt>
<dd>a variable selection method that starts with a null model, and then runs simple linear regressions on all predictors <span class="math inline">\(p\)</span> and adding the one that results in the lowest RSS; repeated until some threshold is reached
</dd>
<dt>backwards selection (79)</dt>
<dd>a variable selection method that starts with a model with all predictors, and removing the one with the lowest <span class="math inline">\(p\)</span>-value until all remaining predictors are significant, whether by <span class="math inline">\(p\)</span>-value or some other criterion
</dd>
<dt>mixed selection (79)</dt>
<dd>a hybrid approach starting with a null model, adding predictors one at a time that produce the best fit, and removing any that acquire a larger <span class="math inline">\(p\)</span>-value in the process until all predictors are added or eliminated
</dd>
<dt>interaction (81)</dt>
<dd>when predictors affect each other, in addition to providing their own effect on the model
</dd>
<dt>confidence interval (82)</dt>
<dd>a range with a percentage component in which there is that percentage chance that the true value of an estimated parameter lies; a 95% confidence interval is a range in which we can be 95% certain <span class="math inline">\(f(X)\)</span> will be found
</dd>
<dt>prediction interval (82)</dt>
<dd>similar to confidence interval, but a prediction range within which we are <span class="math inline">\(X\)</span>% certain that any singular future observation will fall, rather than a statistic like an overall mean; a 95% prediction interval is a range in which we are confident that 95% of future observations will fall. Prediction ranges are substantially wider than confidence intervals.
</dd>
<dt>qualitative predictor / factor (83)</dt>
<dd>a categorical predictor with a fixed number of factors, like “yes” / “no” or “red” / “yellow” / “green”
</dd>
<dt>dummy variable (83)</dt>
<dd>a numeric representation of a factor to use in a model, as in representing “yes” / “no” factor variables as 1 / 0 in a regression
</dd>
<dt>baseline (86)</dt>
<dd>the factor level where there is no dummy variable; a factor with 3 levels will use 2 dummy variables, with the factor’s absence signifying the 3rd value (usually 0)
</dd>
<dt>additivity assumption (87)</dt>
<dd>the assumption that the association between a predictor <span class="math inline">\(X\)</span> and the response <span class="math inline">\(Y\)</span> does not depend on the value of other predictors; used by the standard linear regression model
</dd>
<dt>linearity assumption (87)</dt>
<dd>the assumption, also used by the standard linear regression model, that unit changes in <span class="math inline">\(X_j\)</span> result in the same change to Y regardless of its value
</dd>
<dt>interaction term (88)</dt>
<dd>the product of two predictors in a multiple regression model, quantifying their effect on each other
</dd>
<dt>main effect (89)</dt>
<dd>isolated effects; the effect of a single predictor on the outcome
</dd>
<dt>hierarchical principle (89)</dt>
<dd>the principle that main effects should be left in a model even if they are statistically insignificant, if they are also part of an interaction that is significant
</dd>
<dt>polynomial regression (91)</dt>
<dd>an extension of linear regression to accommodate non-linear relationships
</dd>
<dt>residual plot (93)</dt>
<dd>a plot of the residuals or errors (<span class="math inline">\(e_i = y_i - \hat{y}_i\)</span>), used to check for non-linearity (a potential problem that would likely indicate something was missed in the model)
</dd>
<dt>time series (94)</dt>
<dd>data consisting of observation made at discrete points in time
</dd>
<dt>tracking (95)</dt>
<dd>when (residuals / variables?) tend to have similar values
</dd>
<dt>heteroscedasticity (96)</dt>
<dd>non-constant variances in errors; “unequal scatter”
</dd>
<dt>homoscedasticity (extra)</dt>
<dd>constant variances in errors; follows the assumption of equal variance required by most methods
</dd>
<dt>weighted least squares (97)</dt>
<dd>an extension to ordinary least squares used in circumstances of heteroscedasticity, to weight data points proportionally with the inverse variances
</dd>
<dt>outlier (97)</dt>
<dd>an observation whose value is very far from its predicted value
</dd>
<dt>studentized residual (98)</dt>
<dd>a residual divided by its estimated standard error; observations with student residuals higher than 3 (indicating 3 standard deviations) are likely outliers
</dd>
<dt>high leverage (98)</dt>
<dd>observations with an unusual <span class="math inline">\(x_i\)</span> value, far from other / expected <span class="math inline">\(x\)</span> values
</dd>
<dt>leverage statistic (99)</dt>
<dd>a quantification of a point’s leverage <span class="math display">\[h_i = \frac{1}{n} + \frac{(x_i - \bar{x})^2}{\sum_{i&#39;=1}^{n}(x_{i`} - \bar{x})^2}\]</span>
</dd>
<dt>collinearity (99)</dt>
<dd>when two or more predictor variables are closely related to each other
</dd>
<dt>power (101)</dt>
<dd>the probability of a test correctly detecting a nonzero coefficient (and correctly rejecting <span class="math inline">\(H_0 : \beta_j = 0\)</span>)
</dd>
<dt>multicollinearity (102)</dt>
<dd>when collinearity exists between three or more predictors even when no pair of predictors is collinear (or correlated)
</dd>
<dt>variance inflation factor (102)</dt>
<dd>“the ratio of the variance of <span class="math inline">\(\hat{\beta_j}\)</span> when fitting the full model divided by the variance of <span class="math inline">\(\hat{\beta_j}\)</span> on its own”; smallest possible value of 1 indicates the absence of collinearity, 5-10 indicates a “problematic amount”. <span class="math display">\[\text{VIF}(\hat{\beta_j}) = \frac{1}{1 - {R_{X_j|X_-j}^2}}\]</span> “<span class="math inline">\(R_{X_j|X_-j}^2\)</span> is the <span class="math inline">\(R^2\)</span> from a regression of <span class="math inline">\(X_j\)</span> onto all of the other predictors”
</dd>
<dt>K-nearest neighbors regression (105)</dt>
<dd>a mode of regression that seeks to classify observations by their proximity to classified neighbors
</dd>
<dt>curse of dimensionality (107)</dt>
<dd>when an observation has no nearby neighbors due to a high number of dimensions exponentially increasing the available space for other observations to be spread out in
</dd>
</dl>
<h1 id="chapter-4">Chapter 4</h1>
<dl>
<dt>qualitative / categorical (129)</dt>
<dd>interchangeable term for a variable with a non-quantitative value, such as color
</dd>
<dt>classification (129)</dt>
<dd>predicting a qualitative response for an observation
</dd>
<dt>classifier (129)</dt>
<dd>a classification technique, such as: logistic regression, linear discriminant analysis, quadratic discriminant analysis, naive Bayes, and K-nearest neighbors
</dd>
<dt>logistic function (134)</dt>
<dd>a specific function returning an S-shaped curve with values between 0 and 1, used in logistic regression <span class="math display">\[p(X) = \frac{e^{\beta_0 + \beta_1X}}{1 + e^{\beta_0 + \beta_1X}}\]</span>
</dd>
<dt>odds (134)</dt>
<dd>the likelihood of a particular outcome: the ratio of the number of results that produce the outcome versus the number that do not, between 0 and <span class="math inline">\(\infty\)</span> (very low or very high probabilities) <span class="math display">\[odds = \frac{p(X)}{1 - p(X)} = e^{\beta_0 + \beta_1X}\]</span> Note: odds is not the same as probability! Odds of 1/4 means a 20% probability, not 25%.
</dd>
</dl>
<p>To convert from odds to probability: divide odds by (1 + odds), as in:</p>
<p><span class="math display">\[\frac{1}{4} \div \left[ 1 + \frac{1}{4} \right] = \frac{1}{4} \div \frac{5}{4} = 1/5 = 0.2\]</span></p>
<p>To convert from probability to odds, divide probability by (1 - probability), as in: <span class="math display">\[\frac{1}{5} \div \left[ 1 - \frac{1}{5} \right] = \frac{1}{5} \div \frac{4}{5} = \frac{1}{5} \times \frac{5}{4} = 1/4 = 0.25\]</span> log odds / logit (135) : the log of the odds <span class="math display">\[\text{log} \left( \frac{p(X)}{1 - p(X)} \right)\]</span></p>
<dl>
<dt>likelihood function (135)</dt>
<dd>a function that produces the closest possible match of a set of observations, for use in predicting the classifications of other points hairy equation not rendered
</dd>
<dt>confounding (139)</dt>
<dd>when predictors correlate; usually this is something to work to avoid
</dd>
<dt>multinomial logistic regression (140)</dt>
<dd>logistic regression into more than 2 categories
</dd>
<dt>softmax coding (141)</dt>
<dd>an alternative coding for multiple logistic regression that treats all classes symmetrically, rather than establishing one as a baseline
</dd>
<dt>(probability) density function (142)</dt>
<dd>a function returning the likelihood of a particular value occurring in a given sample, between 0 and 1; often used in pairs to establish likelihood of a value within a range rather than the likelihood of an infinitely-thin single “slice”
</dd>
<dt>prior (142)</dt>
<dd>the probability that a random observation comes from class <span class="math inline">\(k\)</span>
</dd>
<dt>posterior (142)</dt>
<dd>the probability that an observation belongs to a class <span class="math inline">\(k\)</span> given its predictor value
</dd>
<dt>normal / Gaussian (143)</dt>
<dd>characterized by a bell-shaped curve, not uniformly distributed but tending towards a likeliest/central value
</dd>
<dt>overfitting (148)</dt>
<dd>mapping too closely to idiosyncrasies in training data, increasing variance in a model
</dd>
<dt>null classifier (148)</dt>
<dd>a classifier that always predicts a zero or null status
</dd>
<dt>confusion matrix (148)</dt>
<dd>a matrix showing how many predictions were made, and how accurate the classifications were (predicted x actual, hits on TL-BR diagonal and misses on BL-TR diagonal)
</dd>
<dt>sensitivity (149)</dt>
<dd>the percentage of a class (like defaulters) that is correctly identified
</dd>
<dt>specificity (149)</dt>
<dd>the percentage of a different class (like non-defaulters) that is correctly identified
</dd>
<dt>ROC curve (150)</dt>
<dd>Receiver Operating Characteristics; name of a curve showing the overall performance of a classifier resembling the top left corner of a rounded rectangle; area under the curve (AUC) indicates the percentage of correct classifications; the closer it is to square, the bigger the AUC, the better the classifier
</dd>
<dt>marginal distribution (155)</dt>
<dd>the distribution of an individual predictor
</dd>
<dt>joint distribution (155)</dt>
<dd>the association between different predictors
</dd>
<dt>kernel density estimator (156)</dt>
<dd>“essentially a smoothed version of a histogram”
</dd>
</dl>
<h1 id="chapter-5">Chapter 5</h1>
<dl>
<dt>model assessment (197)</dt>
<dd>the process of evaluating a model’s performance
</dd>
<dt>model selection (197)</dt>
<dd>the process of selecting the proper level of flexibility for a model
</dd>
<dt>validation set approach (198)</dt>
<dd>randomly dividing a set of observations into a training set and a validation or hold-out set, to assess the test error rate
</dd>
<dt>leave one out cross-validation (LOOCV) (200)</dt>
<dd>using a single observation for a validation set and the rest as a training set
</dd>
<dt>k-fold cross-validation (CV) (203)</dt>
<dd>dividing a set of observation into <span class="math inline">\(k\)</span> groups of approximately equal size, using the first as a validation set and fitting the method on the remaining <span class="math inline">\(k-1\)</span> folds
</dd>
<dt>bootstrap (209)</dt>
<dd>a tool to quantify the uncertainty associated with a given estimator or statistical learning method
</dd>
<dt>sampling with replacement (211)</dt>
<dd>picking from a set without removing the picked elements
</dd>
</dl>
<div class="sourceCode" id="cb1"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p><a href="http://faculty.ucr.edu/~hanneman/nettext/C1_Social_Network_Data.html" class="uri">http://faculty.ucr.edu/~hanneman/nettext/C1_Social_Network_Data.html</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
